Introduced by Dwork et al., this mechanism adds noise drawn from a [[Laplace distribution]]:

[![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Laplace_mechanism.png/500px-Laplace_mechanism.png)](https://en.wikipedia.org/wiki/File:Laplace_mechanism.png)

Laplace mechanism offering .5-differential privacy for a function with sensitivity 1.

>Formally, a randomized algorithm A is (**ϵ,δ)-differentially private** if for all datasets D and D′ differing in **one record**, and for all outputs S:
>$\Pr[A(D) \in S] \le e^\epsilon \Pr[A(D') \in S] + \delta$
>ϵ (epsilon) controls **privacy loss**. Smaller ϵ → stronger privacy.
  δ allows a small probability of failure (often set to near zero).


![{\displaystyle {\mathcal {M}}_{\mathrm {Lap} }(x,f,\epsilon )=f(x)+\mathrm {Lap} \left(\mu =0,b={\frac {\Delta f}{\epsilon }}\right),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/03a0a1a0e3a691d0f9b07666b31fbda0e9e49a58)

where ![{\displaystyle \mu }](https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161) is the expectation of the Laplace distribution and ![{\displaystyle b}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f11423fbb2e967f986e36804a8ae4271734917c3) is the scale parameter. Roughly speaking, a small-scale noise should suffice for a weak privacy constraint (corresponding to a large value of ![{\displaystyle \epsilon }](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3837cad72483d97bcdde49c85d3b7b859fb3fd2)), while a greater level of noise would provide a greater degree of uncertainty in what was the original input (corresponding to a small value of ϵ![{\displaystyle \epsilon }](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3837cad72483d97bcdde49c85d3b7b859fb3fd2)).

To argue that the mechanism satisfies ϵ-differential privacy, it suffices to show that the output distribution of ![{\displaystyle {\mathcal {M}}_{\mathrm {Lap} }(x,f,\epsilon )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1aea65cd8bfecf6bcf9dda4a28b6981fe5f0b2ea) is _close in a multiplicative sense_ to ![{\displaystyle {\mathcal {M}}_{\mathrm {Lap} }(y,f,\epsilon )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e93c28648485114ef75597b39a9f6f557beb9883) everywhere. ![{\displaystyle {\begin{aligned}{\frac {\mathrm {Pr} ({\mathcal {M}}_{\mathrm {Lap} }(x,f,\epsilon )=z)}{\mathrm {Pr} ({\mathcal {M}}_{\mathrm {Lap} }(y,f,\epsilon )=z)}}&={\frac {\mathrm {Pr} (f(x)+\mathrm {Lap} (0,{\frac {\Delta f}{\epsilon }})=z)}{\mathrm {Pr} (f(y)+\mathrm {Lap} (0,{\frac {\Delta f}{\epsilon }})=z)}}\\&={\frac {\mathrm {Pr} (\mathrm {Lap} (0,{\frac {\Delta f}{\epsilon }})=z-f(x))}{\mathrm {Pr} (\mathrm {Lap} (0,{\frac {\Delta f}{\epsilon }})=z-f(y))}}\\&={\frac {{\frac {1}{2b}}\exp \left(-{\frac {|z-f(x)|}{b}}\right)}{{\frac {1}{2b}}\exp \left(-{\frac {|z-f(y)|}{b}}\right)}}\\&=\exp \left({\frac {|z-f(y)|-|z-f(x)|}{b}}\right)\\&\leq \exp \left({\frac {|f(y)-f(x)|}{b}}\right)\\&\leq \exp \left({\frac {\Delta f}{b}}\right)=\exp(\epsilon ).\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f1d833e05b39bc8c20015e11f4854d7de776a188)The first inequality follows from the triangle inequality and the second from the sensitivity bound. A similar argument gives a lower bound of exp⁡(−ϵ)![{\displaystyle \exp(-\epsilon )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/25adfd700be211fb4e59ee134cb8bfb90ec415b6).

A discrete variant of the Laplace mechanism, called the geometric mechanism, is _universally utility-maximizing_. It means that for any prior (such as auxiliary information or beliefs about data distributions) and any symmetric and monotone univariate loss function, the expected loss of any differentially private mechanism can be matched or improved by running the geometric mechanism followed by a data-independent post-processing transformation. The result also holds for minimax (risk-averse) consumers. No such universal mechanism exists for multi-variate loss functions.