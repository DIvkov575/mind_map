Universal Approximation Theorems (UATs) for sigmoidal networks, which say:
?? necessarily sigmoid - any nonlinear [[Activation Function]]?
- A sufficiently large network with a sigmoidal activation can approximate any continuous function on a compact set.
- do not specify how many neurons are needed,
- do not relate sigmoid parameters (Ax + b learned) to optimal width/depth,
- do not give complexity–accuracy tradeoffs tied to the activation’s parameterization.