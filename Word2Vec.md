
[[Embedding Arithmetic]]
[[Skip-Gram with Negative Sampling (SGNS)]]

$v_w^\top v_c \approx \log p(c \mid w)$
This factorizes a shifted [[Pointwise Mutual Information (PMI)]] Matrix, which is approximately linear in semantic relations. Differences between word vectors correspond to **consistent shifts in co-occurrence statistics**